{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-18T17:37:39.077251Z",
     "iopub.status.busy": "2024-11-18T17:37:39.076854Z",
     "iopub.status.idle": "2024-11-18T17:37:39.083576Z",
     "shell.execute_reply": "2024-11-18T17:37:39.082572Z",
     "shell.execute_reply.started": "2024-11-18T17:37:39.077217Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import warnings\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report, confusion_matrix, ConfusionMatrixDisplay, accuracy_score\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from tensorflow.keras.preprocessing.image import load_img, img_to_array\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "import random"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CREATE TEST-TRAIN SPLIT\n",
    "\n",
    "Creating a good train-test split is essential for evaluating the performance of your machine learning model. Here are some guidelines to help you make an effective train-test split:\n",
    "\n",
    "## Understand the Purpose:\n",
    "\n",
    "The train-test split is used to evaluate the model's performance on unseen data. The training set is used to train the model, while the test set is used to assess its generalization ability.\n",
    "\n",
    "### Hint: Common Split Ratios:\n",
    "\n",
    "Typical split ratios are 70-30, 80-20, or 90-10, where the larger portion is used for training and the smaller portion for testing. For example, an 80-20 split means 80% of the data is used for training and 20% for testing."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "<div style=\"background-color: orange; padding: 10px; border-radius: 5px;\">\n",
    "    TODO \n",
    "    Decide the split by setting the test size variable (0 - 1)\n",
    "</div>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#TODO: Define the test size split for the data\n",
    "test_size = \n",
    "#END TODO"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Prepare the data using using the split ratio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-18T17:37:39.085775Z",
     "iopub.status.busy": "2024-11-18T17:37:39.085452Z",
     "iopub.status.idle": "2024-11-18T17:37:46.598308Z",
     "shell.execute_reply": "2024-11-18T17:37:46.597262Z",
     "shell.execute_reply.started": "2024-11-18T17:37:39.085745Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "train_csv_path = '/kaggle/input/pizza-or-not-pizza-serpentine-competition/train.csv'\n",
    "test_csv_path = '/kaggle/input/pizza-or-not-pizza-serpentine-competition/test.csv'\n",
    "images_dir = '/kaggle/input/pizza-or-not-pizza-serpentine-competition/images/images'\n",
    "\n",
    "# Load train and test CSVs\n",
    "train_df = pd.read_csv(train_csv_path)\n",
    "test_df = pd.read_csv(test_csv_path)\n",
    "\n",
    "\n",
    "# Helper function to load images\n",
    "def load_images(df, images_dir, img_size=(224, 224)):\n",
    "    images = []\n",
    "    labels = []\n",
    "    for _, row in df.iterrows():\n",
    "        img_path = os.path.join(images_dir, row['id'])\n",
    "        img = load_img(img_path, target_size=img_size)  # Resize image\n",
    "        img_array = img_to_array(img) / 255.0  # Normalize to [0, 1]\n",
    "        images.append(img_array)\n",
    "        if 'label' in row:  # Only include labels for training data\n",
    "            labels.append(row['label'])\n",
    "    return np.array(images), np.array(labels) if labels else None\n",
    "\n",
    "# Load training images and labels\n",
    "X_train, y_train = load_images(train_df, images_dir)\n",
    "\n",
    "# Load test images (no labels)\n",
    "X_test, _ = load_images(test_df, images_dir)\n",
    "\n",
    "# Split train data into training and validation sets\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size, random_state=42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-18T17:37:46.599803Z",
     "iopub.status.busy": "2024-11-18T17:37:46.599500Z",
     "iopub.status.idle": "2024-11-18T17:37:46.605868Z",
     "shell.execute_reply": "2024-11-18T17:37:46.604759Z",
     "shell.execute_reply.started": "2024-11-18T17:37:46.599772Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "print(f\"Train data shape: {X_train.shape}, Train labels shape: {y_train.shape}\")\n",
    "print(f\"Validation data shape: {X_val.shape}, Validation labels shape: {y_val.shape}\")\n",
    "print(f\"Test data shape: {X_test.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-18T17:37:46.608310Z",
     "iopub.status.busy": "2024-11-18T17:37:46.607998Z",
     "iopub.status.idle": "2024-11-18T17:37:46.625134Z",
     "shell.execute_reply": "2024-11-18T17:37:46.623915Z",
     "shell.execute_reply.started": "2024-11-18T17:37:46.608280Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "try:\n",
    "    # Detect TPUs\n",
    "    tpu = tf.distribute.cluster_resolver.TPUClusterResolver()\n",
    "    print('Running on TPU ', tpu.master())\n",
    "    # Connect to the TPU cluster\n",
    "    tf.config.experimental_connect_to_cluster(tpu)\n",
    "    tf.tpu.experimental.initialize_tpu_system(tpu)\n",
    "    strategy = tf.distribute.TPUStrategy(tpu)\n",
    "except ValueError:\n",
    "    # If TPU is not available, fallback to default strategy\n",
    "    strategy = tf.distribute.get_strategy()\n",
    "    print(\"Using default strategy\")\n",
    "\n",
    "print(f\"Number of accelerators: {strategy.num_replicas_in_sync}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-18T17:37:46.626677Z",
     "iopub.status.busy": "2024-11-18T17:37:46.626349Z",
     "iopub.status.idle": "2024-11-18T17:37:47.817922Z",
     "shell.execute_reply": "2024-11-18T17:37:47.816758Z",
     "shell.execute_reply.started": "2024-11-18T17:37:46.626646Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Select random indices for 'pizza' (label=1) and 'not_pizza' (label=0)\n",
    "num_images = 5  # Number of images to display from each class\n",
    "\n",
    "# Separate image IDs by label\n",
    "pizza_ids = train_df[train_df['label'] == 1]['id'].values\n",
    "not_pizza_ids = train_df[train_df['label'] == 0]['id'].values\n",
    "\n",
    "# Randomly sample image IDs\n",
    "random_pizza_ids = random.sample(list(pizza_ids), num_images)\n",
    "random_not_pizza_ids = random.sample(list(not_pizza_ids), num_images)\n",
    "\n",
    "# Create subplots for displaying images\n",
    "plt.figure(figsize=(12, 6))\n",
    "for i, image_id in enumerate(random_pizza_ids + random_not_pizza_ids):\n",
    "    # Determine label\n",
    "    label = 'Pizza' if i < num_images else 'Not Pizza'\n",
    "\n",
    "    # Load the image\n",
    "    img_path = os.path.join(images_dir, image_id)\n",
    "    img = load_img(img_path, target_size=(224, 224))  # Adjust target size if needed\n",
    "    img_array = img_to_array(img) / 255.0  # Normalize for display\n",
    "\n",
    "    # Display the image\n",
    "    plt.subplot(2, num_images, i + 1)\n",
    "    plt.imshow(img_array)\n",
    "    plt.title(label)\n",
    "    plt.axis('off')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CHOOSE BATCH SIZE\n",
    "\n",
    "Choosing the right batch size is important for the efficiency and performance of your machine learning model. Here are some guidelines to help you choose a good batch size:\n",
    "\n",
    "## Understand Batch Size\n",
    "\n",
    "The batch size is the number of training examples used in one iteration of model training. It determines how often the model's weights are updated.\n",
    "\n",
    "## Common Batch Sizes\n",
    "\n",
    "<div style=\"background-color: orange; padding: 10px; border-radius: 5px;\">\n",
    " TODO \n",
    "Common batch sizes are powers of 2, such as 16, 32, 64, 128, and 256. These sizes are often chosen because they align well with the memory architecture of modern GPUs.\n",
    "</div>\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-18T17:38:08.837029Z",
     "iopub.status.busy": "2024-11-18T17:38:08.836616Z",
     "iopub.status.idle": "2024-11-18T17:38:10.019394Z",
     "shell.execute_reply": "2024-11-18T17:38:10.018260Z",
     "shell.execute_reply.started": "2024-11-18T17:38:08.836993Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Image Data Generators for training and validation with data augmentation\n",
    "\n",
    "#TODO: Define batch_size\n",
    "batch_size = \n",
    "#END TODO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = tf.data.Dataset.from_tensor_slices((X_train, y_train))\n",
    "train_dataset = train_dataset.shuffle(buffer_size=1024).batch(batch_size)\n",
    "\n",
    "val_dataset = tf.data.Dataset.from_tensor_slices((X_val, y_val))\n",
    "val_dataset = val_dataset.batch(batch_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SET LEARNING RATE\n",
    "<div style=\"background-color: orange; padding: 10px; border-radius: 5px;\">\n",
    " TODO \n",
    "Hint: Begin with a small learning rate, such as `0.001` or `0.0001`. This ensures that the model parameters are updated slowly and helps avoid overshooting the optimal solution\n",
    "</div>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-18T17:38:18.468371Z",
     "iopub.status.busy": "2024-11-18T17:38:18.467990Z",
     "iopub.status.idle": "2024-11-18T17:38:18.473301Z",
     "shell.execute_reply": "2024-11-18T17:38:18.472037Z",
     "shell.execute_reply.started": "2024-11-18T17:38:18.468337Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "#TODO: Define the learning rate of the model\n",
    "rate_learning = \n",
    "#END TODO"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DEFINE MODEL ARCHITECTURE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(you can add or remove layers, just make sure that the dimensionality matches)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-18T17:38:41.114022Z",
     "iopub.status.busy": "2024-11-18T17:38:41.113048Z",
     "iopub.status.idle": "2024-11-18T17:38:41.652831Z",
     "shell.execute_reply": "2024-11-18T17:38:41.651832Z",
     "shell.execute_reply.started": "2024-11-18T17:38:41.113980Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Define the CNN model\n",
    "\n",
    "#TODO: Define Model architecture\n",
    "with strategy.scope():\n",
    "    model = Sequential([\n",
    "        Conv2D(32, (3, 3), activation='relu', \n",
    "               input_shape=(224, 224, 3)),\n",
    "        MaxPooling2D(2, 2),\n",
    "    \n",
    "        Conv2D(64, (3, 3), activation='relu'),\n",
    "        MaxPooling2D(2, 2),\n",
    "    \n",
    "        Flatten(),\n",
    "        Dense(64, activation='relu'),\n",
    "        Dropout(0.5),\n",
    "        Dense(1, activation='sigmoid')  # Binary classification\n",
    "    ])\n",
    "    #END TODO\n",
    "    model.compile(optimizer=Adam(learning_rate=rate_learning),\n",
    "                   \n",
    "                  loss='binary_crossentropy',\n",
    "                  metrics=['accuracy'])\n",
    "\n",
    "# Model summary\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DEFINE PATIENCE FOR EARLY STOPPING\n",
    "\n",
    "Early stopping is a technique used to prevent overfitting by halting the training process when the model's performance on a validation set stops improving. The patience parameter is a key component of early stopping. Here are some guidelines to help you define the patience for early stopping:\n",
    "\n",
    "## Understand Patience:\n",
    "\n",
    "Patience is the number of epochs to wait after the last improvement in the monitored metric (e.g., validation loss) before stopping the training. If the metric does not improve for a specified number of epochs, training is stopped.\n",
    "\n",
    "### Hint: Start with a Baseline:\n",
    "\n",
    "<div style=\"background-color: orange; padding: 10px; border-radius: 5px;\">\n",
    " TODO \n",
    "Begin with a baseline patience value, such as 5 or 10 epochs. This provides a starting point to observe the model's performance and training behavior.\n",
    "</div>\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-18T17:38:51.666233Z",
     "iopub.status.busy": "2024-11-18T17:38:51.665832Z",
     "iopub.status.idle": "2024-11-18T17:38:51.671008Z",
     "shell.execute_reply": "2024-11-18T17:38:51.669944Z",
     "shell.execute_reply.started": "2024-11-18T17:38:51.666201Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Early stopping to prevent overfitting\n",
    "\n",
    "#TODO: Define patience for early stopping\n",
    "amount_of_patience = \n",
    "#END TODO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "early_stopping = EarlyStopping(monitor='val_loss', patience = amount_of_patience, restore_best_weights=True, verbose=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DEFINE NUMBER OF EPOCH FOR TRAINING\n",
    "Choosing the right number of epochs is crucial for training a machine learning model effectively. Here are some guidelines to help you determine a suitable number of epochs:\n",
    "\n",
    "## Understand Epochs:\n",
    "\n",
    "An epoch is one complete pass through the entire training dataset. During each epoch, the model's weights are updated based on the training data.\n",
    "\n",
    "### Hint: Start with a baseline\n",
    "\n",
    "<div style=\"background-color: orange; padding: 10px; border-radius: 5px;\">\n",
    "    TODO \n",
    "    Begin with a baseline number of epochs, such as 10, 50, or 100. This provides a starting point to observe the model's performance and training behavior.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-18T17:38:57.789695Z",
     "iopub.status.busy": "2024-11-18T17:38:57.789306Z",
     "iopub.status.idle": "2024-11-18T17:51:08.892938Z",
     "shell.execute_reply": "2024-11-18T17:51:08.891895Z",
     "shell.execute_reply.started": "2024-11-18T17:38:57.789661Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Train the model\n",
    "\n",
    "#TODO: Define the number of epochs\n",
    "epochs = \n",
    "#END TODO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "history = model.fit(\n",
    "    train_dataset,\n",
    "    validation_data=val_dataset,\n",
    "    epochs=epochs,\n",
    "    callbacks=[early_stopping],\n",
    "    verbose=1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-18T17:51:20.209692Z",
     "iopub.status.busy": "2024-11-18T17:51:20.209323Z",
     "iopub.status.idle": "2024-11-18T17:51:20.643103Z",
     "shell.execute_reply": "2024-11-18T17:51:20.641828Z",
     "shell.execute_reply.started": "2024-11-18T17:51:20.209662Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Plot training and validation accuracy and loss\n",
    "acc = history.history['accuracy']\n",
    "val_acc = history.history['val_accuracy']\n",
    "loss = history.history['loss']\n",
    "val_loss = history.history['val_loss']\n",
    "\n",
    "plt.figure(figsize=(12, 5))\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(acc, label='Training Accuracy')\n",
    "plt.plot(val_acc, label='Validation Accuracy')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.legend()\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(loss, label='Training Loss')\n",
    "plt.plot(val_loss, label='Validation Loss')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-18T17:51:23.479554Z",
     "iopub.status.busy": "2024-11-18T17:51:23.479166Z",
     "iopub.status.idle": "2024-11-18T17:51:33.396813Z",
     "shell.execute_reply": "2024-11-18T17:51:33.395516Z",
     "shell.execute_reply.started": "2024-11-18T17:51:23.479518Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Evaluate the model on the validation set\n",
    "print(\"\\nEvaluating on Validation Set:\")\n",
    "val_loss, val_accuracy = model.evaluate(val_dataset, verbose=1)\n",
    "print(f'Validation accuracy: {val_accuracy * 100:.2f}%')\n",
    "\n",
    "# Make predictions on the validation set\n",
    "y_val_pred_probs = model.predict(val_dataset)\n",
    "y_val_pred = (y_val_pred_probs > 0.5).astype(int).flatten()\n",
    "y_val_true = np.concatenate([y for x, y in val_dataset], axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-18T17:52:16.137837Z",
     "iopub.status.busy": "2024-11-18T17:52:16.137442Z",
     "iopub.status.idle": "2024-11-18T17:52:16.404046Z",
     "shell.execute_reply": "2024-11-18T17:52:16.402961Z",
     "shell.execute_reply.started": "2024-11-18T17:52:16.137800Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Confusion Matrix for Validation Set\n",
    "print(\"\\nConfusion Matrix for Validation Set:\")\n",
    "val_cm = confusion_matrix(y_val_true, y_val_pred)\n",
    "ConfusionMatrixDisplay(confusion_matrix=val_cm, display_labels=['Not Pizza', 'Pizza']).plot(cmap=plt.cm.Blues)\n",
    "plt.title('Confusion Matrix for Validation Set')\n",
    "plt.show()\n",
    "\n",
    "# Classification Report for Validation Set\n",
    "print(\"\\nClassification Report for Validation Set:\")\n",
    "print(classification_report(y_val_true, y_val_pred, target_names=['Not Pizza', 'Pizza']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-18T17:52:21.402631Z",
     "iopub.status.busy": "2024-11-18T17:52:21.402220Z",
     "iopub.status.idle": "2024-11-18T17:52:49.191455Z",
     "shell.execute_reply": "2024-11-18T17:52:49.190188Z",
     "shell.execute_reply.started": "2024-11-18T17:52:21.402596Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Load the public dataset (images and labels from train.csv or similar source)\n",
    "X_public, y_public = load_images(train_df, images_dir)  # Ensure correct filtering for public dataset if needed\n",
    "\n",
    "# Predict on the public dataset\n",
    "print(\"\\nEvaluating on Entire Public Dataset:\")\n",
    "y_public_pred_probs = model.predict(X_public)\n",
    "y_public_pred = (y_public_pred_probs > 0.5).astype(int).flatten()\n",
    "\n",
    "# Calculate the accuracy\n",
    "public_accuracy = accuracy_score(y_public, y_public_pred)\n",
    "print(f'Accuracy on the entire public dataset: {public_accuracy * 100:.2f}%')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-18T17:53:42.547435Z",
     "iopub.status.busy": "2024-11-18T17:53:42.547039Z",
     "iopub.status.idle": "2024-11-18T17:53:42.751553Z",
     "shell.execute_reply": "2024-11-18T17:53:42.750541Z",
     "shell.execute_reply.started": "2024-11-18T17:53:42.547400Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Confusion Matrix\n",
    "print(\"\\nConfusion Matrix for Entire Public Dataset:\")\n",
    "public_cm = confusion_matrix(y_public, y_public_pred)\n",
    "ConfusionMatrixDisplay(confusion_matrix=public_cm, display_labels=['Not Pizza', 'Pizza']).plot(cmap=plt.cm.Blues)\n",
    "plt.title('Confusion Matrix for Entire Public Dataset')\n",
    "plt.show()\n",
    "\n",
    "# Classification Report\n",
    "print(\"\\nClassification Report for Entire Public Dataset:\")\n",
    "print(classification_report(y_public, y_public_pred, target_names=['Not Pizza', 'Pizza']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-18T17:53:47.077107Z",
     "iopub.status.busy": "2024-11-18T17:53:47.076697Z",
     "iopub.status.idle": "2024-11-18T17:53:56.645091Z",
     "shell.execute_reply": "2024-11-18T17:53:56.643828Z",
     "shell.execute_reply.started": "2024-11-18T17:53:47.077072Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Generate predictions for test dataset\n",
    "y_test_pred_probs = model.predict(X_test)\n",
    "y_test_pred = (y_test_pred_probs > 0.5).astype(int).flatten()\n",
    "\n",
    "# Prepare submission file\n",
    "submission = pd.DataFrame({\n",
    "    'id': test_df['id'],\n",
    "    'label': y_test_pred\n",
    "})\n",
    "submission.to_csv('submission.csv', index=False)\n",
    "print(\"Submission file saved as submission.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-18T17:54:32.147785Z",
     "iopub.status.busy": "2024-11-18T17:54:32.147062Z",
     "iopub.status.idle": "2024-11-18T17:54:32.332243Z",
     "shell.execute_reply": "2024-11-18T17:54:32.331254Z",
     "shell.execute_reply.started": "2024-11-18T17:54:32.147742Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Save the model for future use\n",
    "model.save('/kaggle/working/pizza_not_pizza_model.h5')"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "none",
   "dataSources": [
    {
     "databundleVersionId": 10205157,
     "sourceId": 88885,
     "sourceType": "competition"
    }
   ],
   "dockerImageVersionId": 30786,
   "isGpuEnabled": false,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
